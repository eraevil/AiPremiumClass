{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##第六周作业1：实验使用不同的RNN结构，实现一个人脸图像分类器。至少对比2种以上结构训练损失和准确率差异，如：LSTM、GRU、RNN、BiRNN等。要求使用tensorboard，提交代码及run目录和可视化截图。\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_olivetti_faces.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "from torchvision.transforms.v2 import ToTensor     # 转换图像数据为张量\n",
    "import torch as torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_Classifier(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        self.rnn=nn.LSTM(\n",
    "            input_size=64,\n",
    "            hidden_size=128,\n",
    "            bias=True,\n",
    "            num_layers=3,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc=nn.Linear(128,40)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        outputs,l_h=self.rnn(x)\n",
    "\n",
    "        out=self.fc(outputs[:,-1,:])\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 4096)\n",
      "(400,)\n",
      "(400, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "olivetti_faces = fetch_olivetti_faces(data_home='./face_data', shuffle=True)\n",
    "print(olivetti_faces.data.shape)\n",
    "print(olivetti_faces.target.shape)\n",
    "print(olivetti_faces.images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(olivetti_faces.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "##images = torch.tensor(olivetti_faces.data)\n",
    "##targets = torch.tensor(olivetti_faces.target,dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "###划分训练数据和测试数据\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(olivetti_faces.images, olivetti_faces.target, \n",
    "                                                     train_size=0.80, \n",
    "                                                    random_state=100, shuffle=True, stratify=olivetti_faces.target)\n",
    "\n",
    " \n",
    "\n",
    "##参数stratify=olivetti_faces.target 表示安装target分层抽样\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数\n",
    "LR = 1e-3   ##学习率\n",
    "epochs = 80      ##训练次数\n",
    "BATCH_SIZE = 15  ###批次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[0.5082645 , 0.6280992 , 0.6694215 , ..., 0.57024795, 0.57438016,\n",
      "        0.5371901 ],\n",
      "       [0.59090906, 0.6694215 , 0.5       , ..., 0.5661157 , 0.57024795,\n",
      "        0.57438016],\n",
      "       [0.56198347, 0.6280992 , 0.46694216, ..., 0.57024795, 0.58677685,\n",
      "        0.5785124 ],\n",
      "       ...,\n",
      "       [0.16115703, 0.14876033, 0.1446281 , ..., 0.11157025, 0.11157025,\n",
      "        0.11570248],\n",
      "       [0.16115703, 0.15289256, 0.14876033, ..., 0.10743801, 0.10743801,\n",
      "        0.11983471],\n",
      "       [0.14876033, 0.13636364, 0.1446281 , ..., 0.11157025, 0.11983471,\n",
      "        0.12396694]], shape=(64, 64), dtype=float32), np.int64(31))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = [(img,lbl) for img,lbl in zip(X_train, y_train)]\n",
    "print(dataset[0])\n",
    "\n",
    "train_dl = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)  # shuffle=True表示打乱数据\n",
    "\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[0.5247934 , 0.5371901 , 0.5785124 , ..., 0.61157024, 0.59504133,\n",
      "        0.55785125],\n",
      "       [0.5165289 , 0.5206612 , 0.55785125, ..., 0.607438  , 0.58264464,\n",
      "        0.553719  ],\n",
      "       [0.5041322 , 0.5041322 , 0.5289256 , ..., 0.59090906, 0.57438016,\n",
      "        0.553719  ],\n",
      "       ...,\n",
      "       [0.34710744, 0.34710744, 0.34710744, ..., 0.53305787, 0.5247934 ,\n",
      "        0.446281  ],\n",
      "       [0.3429752 , 0.3429752 , 0.3429752 , ..., 0.53305787, 0.5247934 ,\n",
      "        0.42975205],\n",
      "       [0.338843  , 0.338843  , 0.338843  , ..., 0.5289256 , 0.5082645 ,\n",
      "        0.43801653]], shape=(64, 64), dtype=float32), np.int64(4))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###测试集\n",
    "dataset_test = [(img,lbl) for img,lbl in zip(X_test, y_test)]\n",
    "print(dataset_test[0])\n",
    "\n",
    "test_loader = DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=True)  # shuffle=True表示打乱数据\n",
    "\n",
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=RNN_Classifier()  ##实例化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "###定义损失函数和优化器\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(),LR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer=SummaryWriter()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 ,loss: 3.7114\n",
      "epoch:1/80,test accuracy:5.00\n",
      "epoch:10 ,loss: 1.7458\n",
      "epoch:11/80,test accuracy:42.50\n",
      "epoch:20 ,loss: 1.0354\n",
      "epoch:21/80,test accuracy:53.75\n",
      "epoch:30 ,loss: 0.5747\n",
      "epoch:31/80,test accuracy:68.75\n",
      "epoch:40 ,loss: 0.2390\n",
      "epoch:41/80,test accuracy:83.75\n",
      "epoch:50 ,loss: 0.1243\n",
      "epoch:51/80,test accuracy:82.50\n",
      "epoch:60 ,loss: 0.0696\n",
      "epoch:61/80,test accuracy:90.00\n",
      "epoch:70 ,loss: 0.0165\n",
      "epoch:71/80,test accuracy:90.00\n"
     ]
    }
   ],
   "source": [
    "##训练模型\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for img,lbl in train_dl:\n",
    "        optimizer.zero_grad()\n",
    "        outputs=model(img)\n",
    "        loss=criterion(outputs,lbl)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(),max_norm=1.0) ###梯度裁剪\n",
    "\n",
    "        optimizer.step()\n",
    "    if epoch%10==0:\n",
    "        print(f\"epoch:{epoch} ,loss: {loss.item():.4f}\")\n",
    "    model.eval()\n",
    "    ##模型评估\n",
    "    with torch.no_grad():\n",
    "        correct=0\n",
    "        total=0\n",
    "        for img,lbl in test_loader:\n",
    "            outputs=model((img))\n",
    "            _,predicted=torch.max(outputs.data,1)\n",
    "            total+=lbl.size(0)\n",
    "            correct+=(predicted==lbl).sum().item()\n",
    "        accuracy=100*correct/total\n",
    "        if epoch%10==0:\n",
    "            print(f\"epoch:{epoch+1}/{epochs},test accuracy:{accuracy:.2f}\")\n",
    "        writer.add_scalar('test_accracy',accuracy,epoch)\n",
    "        writer.add_scalar('loss',loss.item(),epoch)\n",
    "writer.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ZXD\\AppData\\Local\\Temp\\ipykernel_21280\\1564482467.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_load.load_state_dict(torch.load('rnn_model_params.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###保存全部\n",
    "torch.save(model,'rnn_model.pth')\n",
    "\n",
    "##保存模型参数\n",
    "torch.save(model.state_dict(),'rnn_model_params.pth')\n",
    "\n",
    "##加载模型\n",
    "model_load=RNN_Classifier()\n",
    "model_load.load_state_dict(torch.load('rnn_model_params.pth'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
