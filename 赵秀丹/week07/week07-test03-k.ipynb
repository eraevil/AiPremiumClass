{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11508826,"sourceType":"datasetVersion","datasetId":7216293},{"sourceId":11508945,"sourceType":"datasetVersion","datasetId":7216383}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:47:55.594263Z","iopub.execute_input":"2025-04-22T04:47:55.594522Z","iopub.status.idle":"2025-04-22T04:47:56.578778Z","shell.execute_reply.started":"2025-04-22T04:47:55.594496Z","shell.execute_reply":"2025-04-22T04:47:56.578005Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/sp-comment/douban_comments_sp.pkl\n/kaggle/input/sp-pth/sp_comments_vocab.pth\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nfrom torch.nn.utils.rnn import pad_sequence\ndef build_collate_fun(vocab):\n\n    def collate_func(batch):\n        comments,labels=[],[]\n        for item in batch:\n            token_index=torch.tensor([vocab[tk] for tk in item[0] if tk !=' '])\n            comments.append(token_index)\n            labels.append(item[1])\n        ##padding\n        comments=pad_sequence(comments,batch_first=True,padding_value=0)\n        return comments,torch.tensor(labels,dtype=torch.int64)\n    return collate_func","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:52:44.567478Z","iopub.execute_input":"2025-04-22T04:52:44.567764Z","iopub.status.idle":"2025-04-22T04:52:48.500516Z","shell.execute_reply.started":"2025-04-22T04:52:44.567743Z","shell.execute_reply":"2025-04-22T04:52:48.499741Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"##定义模型\nimport torch.nn as nn\nclass Comments_Classifier(nn.Module):\n\n    def __init__(self, vocab_size, embedding_dim, hidden_size, num_classes):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)  # padding_idx=0\n        self.rnn = nn.LSTM(embedding_dim, hidden_size, batch_first=True)\n        self.fc = nn.Linear(hidden_size, num_classes)\n\n    def forward(self, input_ids):\n        # input_ids: (batch_size, seq_len)\n        # embedded: (batch_size, seq_len, embedding_dim)\n        embedded = self.embedding(input_ids)\n        # output: (batch_size, seq_len, hidden_size)\n        output, (hidden, _) = self.rnn(embedded)\n        output = self.fc(output[:, -1, :])  # 取最后一个时间步的输出\n        return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:53:10.121751Z","iopub.execute_input":"2025-04-22T04:53:10.122163Z","iopub.status.idle":"2025-04-22T04:53:10.127991Z","shell.execute_reply.started":"2025-04-22T04:53:10.122139Z","shell.execute_reply":"2025-04-22T04:53:10.127246Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"###拆分数据集分为训练 测试 验证\nimport random\ndef train_test_split(x,split_rate=0.2):\n    ###测试集和验证集按照1：1拆分 训练集和test集按照split_rate拆分\n    split_size=int(len(x)*(1-split_rate))\n    split_size2=int((int(len(x))-split_size)/2)\n    split_size3=split_size+split_size2\n    split_index=list(range(len(x)))\n    random.shuffle(split_index)\n    x_train=[x[i][0] for i in split_index[:split_size]]\n    y_train=[x[i][1] for i in split_index[:split_size]]\n\n\n    x_test=[x[i][0] for i in split_index[split_size:split_size3]]\n    y_test=[x[i][1] for i in split_index[split_size:split_size3]]\n\n    x_valid=[x[i][0] for i in split_index[split_size3:]]\n    y_valid=[x[i][1] for i in split_index[split_size3:]]\n\n\n    return (x_train,y_train),(x_test,y_test),(x_valid,y_valid)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:53:22.975258Z","iopub.execute_input":"2025-04-22T04:53:22.975802Z","iopub.status.idle":"2025-04-22T04:53:22.982261Z","shell.execute_reply.started":"2025-04-22T04:53:22.975775Z","shell.execute_reply":"2025-04-22T04:53:22.981438Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from torch.utils.tensorboard import SummaryWriter\nwriter=SummaryWriter()\n\ntrain_loss_cnt=0\nval_loss_cnt=0\nval_acc_cnt=0\n\nBATCH_SIZE=100\nEPOCHS=5\nEMBEDING_SIZE=200\nRNN_HIDDEN_SIZE=200\nLEARN_RATE=1e-3\nNUM_LABELS=2\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:53:32.727105Z","iopub.execute_input":"2025-04-22T04:53:32.727405Z","iopub.status.idle":"2025-04-22T04:53:46.859374Z","shell.execute_reply.started":"2025-04-22T04:53:32.727382Z","shell.execute_reply":"2025-04-22T04:53:46.858746Z"}},"outputs":[{"name":"stderr","text":"2025-04-22 04:53:35.334049: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745297615.528475      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745297615.585659      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:53:59.660962Z","iopub.execute_input":"2025-04-22T04:53:59.661803Z","iopub.status.idle":"2025-04-22T04:53:59.741158Z","shell.execute_reply.started":"2025-04-22T04:53:59.661776Z","shell.execute_reply":"2025-04-22T04:53:59.740369Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import pickle\n###还原评论数据\nwith open('/kaggle/input/sp-comment/douban_comments_sp.pkl','rb' ) as f:\n    comments_data=pickle.load(f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:54:22.891237Z","iopub.execute_input":"2025-04-22T04:54:22.892061Z","iopub.status.idle":"2025-04-22T04:54:40.256478Z","shell.execute_reply.started":"2025-04-22T04:54:22.892035Z","shell.execute_reply":"2025-04-22T04:54:40.255854Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def buid_vocab_from_documents(doc):\n    no_repeat_tokens=set()\n    for cmt in doc:\n        no_repeat_tokens.update(cmt[0])\n    tokens=['<PAD>','<UNK>']+list(no_repeat_tokens)\n\n    vocab={ tk:i for i,tk in enumerate(tokens)}\n    return vocab","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:54:47.033496Z","iopub.execute_input":"2025-04-22T04:54:47.033776Z","iopub.status.idle":"2025-04-22T04:54:47.038719Z","shell.execute_reply.started":"2025-04-22T04:54:47.033755Z","shell.execute_reply":"2025-04-22T04:54:47.037985Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"vocab=buid_vocab_from_documents(comments_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:54:50.463414Z","iopub.execute_input":"2025-04-22T04:54:50.463683Z","iopub.status.idle":"2025-04-22T04:54:52.819010Z","shell.execute_reply.started":"2025-04-22T04:54:50.463662Z","shell.execute_reply":"2025-04-22T04:54:52.818364Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"len(vocab)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:55:10.500357Z","iopub.execute_input":"2025-04-22T04:55:10.500962Z","iopub.status.idle":"2025-04-22T04:55:10.505603Z","shell.execute_reply.started":"2025-04-22T04:55:10.500922Z","shell.execute_reply":"2025-04-22T04:55:10.504979Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"14844"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"##数据拆分\n(x_train,y_train),(x_test,y_test),(x_valid,y_valid)=train_test_split(comments_data)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:55:19.543322Z","iopub.execute_input":"2025-04-22T04:55:19.543604Z","iopub.status.idle":"2025-04-22T04:55:21.365535Z","shell.execute_reply.started":"2025-04-22T04:55:19.543583Z","shell.execute_reply":"2025-04-22T04:55:21.364738Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"print(len(x_train))\nprint(len(x_test))\nprint(len(x_valid))\nprint(x_train[0],y_train[0])\nprint(x_test[0],y_test[0])\nprint(x_valid[0],y_valid[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:55:28.350730Z","iopub.execute_input":"2025-04-22T04:55:28.351041Z","iopub.status.idle":"2025-04-22T04:55:28.355666Z","shell.execute_reply.started":"2025-04-22T04:55:28.351017Z","shell.execute_reply":"2025-04-22T04:55:28.354973Z"}},"outputs":[{"name":"stdout","text":"1040700\n130087\n130088\n['▁', '由于', '对', '武', '隆', '印象', '颇', '深', ',', '后半段', '还以为', '擎天柱', '和', '飞', '船', '从', '香港', '炸', '到', '武', '隆', '去了', '。。。'] 0\n['▁', '就觉得', '钢铁侠', '跟', '绿巨人', '的', '打斗', '最', '经典'] 0\n['▁', '一步', '非常不错', '的', '国产动画片', '!'] 0\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ntrain_ds=list(zip(x_train,y_train))\n# 通过Dataset构建DataLoader\ntrain_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, \n                        collate_fn=build_collate_fun(vocab))\n\nvalid_ds=list(zip(x_valid,y_valid))\n# 通过Dataset构建DataLoader\nvalid_dl = DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=True, \n                        collate_fn=build_collate_fun(vocab))\ntest_ds=list(zip(x_test,y_test))\n# 通过Dataset构建DataLoader\ntest_dl = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, \n                        collate_fn=build_collate_fun(vocab))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:55:49.908118Z","iopub.execute_input":"2025-04-22T04:55:49.908418Z","iopub.status.idle":"2025-04-22T04:55:52.131546Z","shell.execute_reply.started":"2025-04-22T04:55:49.908397Z","shell.execute_reply":"2025-04-22T04:55:52.130977Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"###模型构建\n\nmodel = Comments_Classifier(len(vocab), EMBEDING_SIZE, RNN_HIDDEN_SIZE, NUM_LABELS)\n# 定义损失函数和优化器\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=LEARN_RATE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:56:05.801234Z","iopub.execute_input":"2025-04-22T04:56:05.802009Z","iopub.status.idle":"2025-04-22T04:56:08.246961Z","shell.execute_reply.started":"2025-04-22T04:56:05.801983Z","shell.execute_reply":"2025-04-22T04:56:08.246164Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"from tqdm import tqdm\n\ndef train(model,train_dl,criterion,optimizer):\n    global train_loss_cnt\n    model.to(device)\n    model.train()\n    tpbar=tqdm(train_dl)\n    for tokens,labels in tpbar:\n        optimizer.zero_grad()\n        tokens,labels=tokens.to(device),labels.to(device)\n        loss=train_step(model,tokens,labels,criterion)\n        loss.backward()\n        optimizer.step()\n        tpbar.set_description(f\"epoch:{epoch+1} train_loss:{loss.item():.4f}\")\n        writer.add_scalar('train_loss',loss.item(),train_loss_cnt)\n        train_loss_cnt+=1\n\ndef train_step(model,tokens,labels,criterion):\n    logits=model(tokens)\n    loss=criterion(logits,labels)\n    return loss\n    \ndef validate(model,val_dl,criterion):\n    global val_loss_cnt,val_acc_cnt\n    model.to(device)\n    model.eval()\n    tpbar=tqdm(val_dl)\n    total_loss=0\n    total_acc=0\n\n    for tokens,labels in tpbar:\n        tokens,labels=tokens.to(device),labels.to(device)\n        loss,logits=validate_step(model,tokens,labels,criterion)\n        tpbar.set_description(f\"epoch:{epoch+1} val_loss:{loss.item():.4f}\")\n\n        total_loss+=loss.item()\n        total_acc+=(logits.argmax(dim=1)==labels).float().mean()\n    writer.add_scalar('val_avg_loss',total_loss/len(val_dl),val_loss_cnt)\n    val_loss_cnt+=1\n    ##计算准确率\n    writer.add_scalar('val_acc',total_acc/len(val_dl),val_acc_cnt)\n    val_acc_cnt +=1\n         \n\n\ndef validate_step(model,tokens,labels,criterion):\n    logits=model(tokens)\n    loss=criterion(logits,labels)\n    return loss,logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:56:19.350109Z","iopub.execute_input":"2025-04-22T04:56:19.350974Z","iopub.status.idle":"2025-04-22T04:56:19.360263Z","shell.execute_reply.started":"2025-04-22T04:56:19.350941Z","shell.execute_reply":"2025-04-22T04:56:19.359399Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"##训练\nfor epoch in range(EPOCHS):\n    train(model,train_dl,criterion,optimizer)\n    validate(model,valid_dl,criterion)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:56:28.671018Z","iopub.execute_input":"2025-04-22T04:56:28.671261Z","iopub.status.idle":"2025-04-22T05:10:51.164566Z","shell.execute_reply.started":"2025-04-22T04:56:28.671243Z","shell.execute_reply":"2025-04-22T05:10:51.163844Z"}},"outputs":[{"name":"stderr","text":"epoch:1 train_loss:0.2422: 100%|██████████| 10407/10407 [02:42<00:00, 63.93it/s]\nepoch:1 val_loss:0.2104: 100%|██████████| 1301/1301 [00:10<00:00, 129.91it/s]\nepoch:2 train_loss:0.2317: 100%|██████████| 10407/10407 [02:43<00:00, 63.84it/s]\nepoch:2 val_loss:0.2414: 100%|██████████| 1301/1301 [00:10<00:00, 129.83it/s]\nepoch:3 train_loss:0.1629: 100%|██████████| 10407/10407 [02:41<00:00, 64.37it/s]\nepoch:3 val_loss:0.2552: 100%|██████████| 1301/1301 [00:09<00:00, 130.88it/s]\nepoch:4 train_loss:0.2076: 100%|██████████| 10407/10407 [02:42<00:00, 64.11it/s]\nepoch:4 val_loss:0.1441: 100%|██████████| 1301/1301 [00:09<00:00, 133.51it/s]\nepoch:5 train_loss:0.1005: 100%|██████████| 10407/10407 [02:42<00:00, 63.98it/s]\nepoch:5 val_loss:0.1477: 100%|██████████| 1301/1301 [00:09<00:00, 130.24it/s]\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"##保存模型\ntorch.save({'model_state': model.state_dict(),\n            'model_vocab':vocab},'model_jieba.bin')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T05:13:35.726720Z","iopub.execute_input":"2025-04-22T05:13:35.727447Z","iopub.status.idle":"2025-04-22T05:13:35.765475Z","shell.execute_reply.started":"2025-04-22T05:13:35.727421Z","shell.execute_reply":"2025-04-22T05:13:35.764923Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# 创建模型实例\nmodel_test = Comments_Classifier(len(vocab), EMBEDING_SIZE, RNN_HIDDEN_SIZE, NUM_LABELS)\n\n# 加载保存的文件\ncheckpoint = torch.load('model_jieba.bin',weights_only=False)\n\n# 加载模型的状态字典\nmodel_test.load_state_dict(checkpoint['model_state'])\n\n# 加载词汇表\nvocab_test = checkpoint['model_vocab']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T05:13:38.124771Z","iopub.execute_input":"2025-04-22T05:13:38.125352Z","iopub.status.idle":"2025-04-22T05:13:38.175706Z","shell.execute_reply.started":"2025-04-22T05:13:38.125329Z","shell.execute_reply":"2025-04-22T05:13:38.175187Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"###测试模型\ntpbar=tqdm(test_ds)\ni=0\nfor tokens,labels in tpbar:\n    model_test.eval()\n    model_test.to(device)\n    comment1_idx = torch.tensor([vocab_test.get(word, vocab_test['<UNK>']) for word in tokens])\n    comment1_idx = comment1_idx.unsqueeze(0).to(device)  # 添加batch维度    \n    predict=model_test(comment1_idx)\n    if torch.argmax(predict, dim=1).item()==labels:\n        i=i+1\nprint(f\"测试集正确率：{i/len(test_ds):.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T05:13:40.606820Z","iopub.execute_input":"2025-04-22T05:13:40.607318Z","iopub.status.idle":"2025-04-22T05:16:27.621751Z","shell.execute_reply.started":"2025-04-22T05:13:40.607293Z","shell.execute_reply":"2025-04-22T05:16:27.620975Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 130087/130087 [02:47<00:00, 778.93it/s]","output_type":"stream"},{"name":"stdout","text":"测试集正确率：0.9122\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":20}]}