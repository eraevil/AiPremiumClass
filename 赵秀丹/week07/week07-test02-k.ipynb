{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11502846,"sourceType":"datasetVersion","datasetId":7211750},{"sourceId":11502941,"sourceType":"datasetVersion","datasetId":7211818}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-22T03:05:30.735786Z","iopub.execute_input":"2025-04-22T03:05:30.736014Z","iopub.status.idle":"2025-04-22T03:05:32.257483Z","shell.execute_reply.started":"2025-04-22T03:05:30.735991Z","shell.execute_reply":"2025-04-22T03:05:32.256748Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/jieba-pkl/douban_comments_jieba.pkl\n/kaggle/input/jieba-vocab/jieba_comments_vocab.pth\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nfrom torch.nn.utils.rnn import pad_sequence\ndef build_collate_fun(vocab):\n\n    def collate_func(batch):\n        comments,labels=[],[]\n        for item in batch:\n            token_index=torch.tensor([vocab[tk] for tk in item[0] if tk !=' '])\n            comments.append(token_index)\n            labels.append(item[1])\n        ##padding\n        comments=pad_sequence(comments,batch_first=True,padding_value=0)\n        return comments,torch.tensor(labels,dtype=torch.int64)\n    return collate_func","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T03:05:38.744808Z","iopub.execute_input":"2025-04-22T03:05:38.745257Z","iopub.status.idle":"2025-04-22T03:05:42.390188Z","shell.execute_reply.started":"2025-04-22T03:05:38.745234Z","shell.execute_reply":"2025-04-22T03:05:42.389457Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"##定义模型\nimport torch.nn as nn\nclass Comments_Classifier(nn.Module):\n\n    def __init__(self, vocab_size, embedding_dim, hidden_size, num_classes):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)  # padding_idx=0\n        self.rnn = nn.LSTM(embedding_dim, hidden_size, batch_first=True)\n        self.fc = nn.Linear(hidden_size, num_classes)\n\n    def forward(self, input_ids):\n        # input_ids: (batch_size, seq_len)\n        # embedded: (batch_size, seq_len, embedding_dim)\n        embedded = self.embedding(input_ids)\n        # output: (batch_size, seq_len, hidden_size)\n        output, (hidden, _) = self.rnn(embedded)\n        output = self.fc(output[:, -1, :])  # 取最后一个时间步的输出\n        return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T03:06:50.649515Z","iopub.execute_input":"2025-04-22T03:06:50.650419Z","iopub.status.idle":"2025-04-22T03:06:50.655609Z","shell.execute_reply.started":"2025-04-22T03:06:50.650393Z","shell.execute_reply":"2025-04-22T03:06:50.655047Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"###拆分数据集分为训练 测试 验证\nimport random\ndef train_test_split(x,split_rate=0.2):\n    ###测试集和验证集按照1：1拆分 训练集和test集按照split_rate拆分\n    split_size=int(len(x)*(1-split_rate))\n    split_size2=int((int(len(x))-split_size)/2)\n    split_size3=split_size+split_size2\n    split_index=list(range(len(x)))\n    random.shuffle(split_index)\n    x_train=[x[i][0] for i in split_index[:split_size]]\n    y_train=[x[i][1] for i in split_index[:split_size]]\n\n\n    x_test=[x[i][0] for i in split_index[split_size:split_size3]]\n    y_test=[x[i][1] for i in split_index[split_size:split_size3]]\n\n    x_valid=[x[i][0] for i in split_index[split_size3:]]\n    y_valid=[x[i][1] for i in split_index[split_size3:]]\n\n\n    return (x_train,y_train),(x_test,y_test),(x_valid,y_valid)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T03:07:16.751511Z","iopub.execute_input":"2025-04-22T03:07:16.752033Z","iopub.status.idle":"2025-04-22T03:07:16.757799Z","shell.execute_reply.started":"2025-04-22T03:07:16.752008Z","shell.execute_reply":"2025-04-22T03:07:16.757028Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from torch.utils.tensorboard import SummaryWriter\nwriter=SummaryWriter()\n\ntrain_loss_cnt=0\nval_loss_cnt=0\nval_acc_cnt=0\n\nBATCH_SIZE=100\nEPOCHS=5\nEMBEDING_SIZE=200\nRNN_HIDDEN_SIZE=200\nLEARN_RATE=1e-3\nNUM_LABELS=2\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T03:07:20.949246Z","iopub.execute_input":"2025-04-22T03:07:20.949890Z","iopub.status.idle":"2025-04-22T03:07:34.340067Z","shell.execute_reply.started":"2025-04-22T03:07:20.949866Z","shell.execute_reply":"2025-04-22T03:07:34.339514Z"}},"outputs":[{"name":"stderr","text":"2025-04-22 03:07:23.486319: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745291243.678659      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745291243.735462      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T03:07:34.340974Z","iopub.execute_input":"2025-04-22T03:07:34.341485Z","iopub.status.idle":"2025-04-22T03:07:34.401225Z","shell.execute_reply.started":"2025-04-22T03:07:34.341466Z","shell.execute_reply":"2025-04-22T03:07:34.400418Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import pickle\n###还原评论数据\nwith open('/kaggle/input/jieba-pkl/douban_comments_jieba.pkl','rb' ) as f:\n    comments_data=pickle.load(f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T03:09:08.877108Z","iopub.execute_input":"2025-04-22T03:09:08.877294Z","iopub.status.idle":"2025-04-22T03:09:24.454419Z","shell.execute_reply.started":"2025-04-22T03:09:08.877280Z","shell.execute_reply":"2025-04-22T03:09:24.453873Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def buid_vocab_from_documents(doc):\n    no_repeat_tokens=set()\n    for cmt in doc:\n        no_repeat_tokens.update(cmt[0])\n    tokens=['<PAD>','<UNK>']+list(no_repeat_tokens)\n\n    vocab={ tk:i for i,tk in enumerate(tokens)}\n    return vocab","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T03:09:48.800516Z","iopub.execute_input":"2025-04-22T03:09:48.801222Z","iopub.status.idle":"2025-04-22T03:09:48.805034Z","shell.execute_reply.started":"2025-04-22T03:09:48.801199Z","shell.execute_reply":"2025-04-22T03:09:48.804277Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"vocab=buid_vocab_from_documents(comments_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T03:09:51.899723Z","iopub.execute_input":"2025-04-22T03:09:51.900369Z","iopub.status.idle":"2025-04-22T03:09:54.721128Z","shell.execute_reply.started":"2025-04-22T03:09:51.900345Z","shell.execute_reply":"2025-04-22T03:09:54.720585Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"len(vocab)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T03:09:56.080309Z","iopub.execute_input":"2025-04-22T03:09:56.081012Z","iopub.status.idle":"2025-04-22T03:09:56.086100Z","shell.execute_reply.started":"2025-04-22T03:09:56.080988Z","shell.execute_reply":"2025-04-22T03:09:56.085588Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"282378"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"##数据拆分\n(x_train,y_train),(x_test,y_test),(x_valid,y_valid)=train_test_split(comments_data)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T03:09:57.945529Z","iopub.execute_input":"2025-04-22T03:09:57.945829Z","iopub.status.idle":"2025-04-22T03:09:59.625307Z","shell.execute_reply.started":"2025-04-22T03:09:57.945807Z","shell.execute_reply":"2025-04-22T03:09:59.624754Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"print(len(x_train))\nprint(len(x_test))\nprint(len(x_valid))\nprint(x_train[0],y_train[0])\nprint(x_test[0],y_test[0])\nprint(x_valid[0],y_valid[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T03:10:01.737533Z","iopub.execute_input":"2025-04-22T03:10:01.738263Z","iopub.status.idle":"2025-04-22T03:10:01.742713Z","shell.execute_reply.started":"2025-04-22T03:10:01.738234Z","shell.execute_reply":"2025-04-22T03:10:01.741936Z"}},"outputs":[{"name":"stdout","text":"1040700\n130087\n130088\n[' ', '我', '只能', '说', ' ', '都', '是', '新', '演员', ' ', '新', '导演', ' ', '新', '编剧', ' ', '这样', '的', '完成度', '已经', '不错', '了'] 0\n[' ', '讲真', '，', '我', '是', '吴亦凡', '的', '粉丝', '。', '但是', '唐僧', '真的', '觉得', '文章', '演', '的', '比', '他', '好', '太', '多', '。', '一下子', '用', '那么', '多', '新人', '。', '真的', '失落', '好多', '。', '没有', '舒淇', '的', '串场', '，', '这部', '真的', '没有', '一点', '感动', '点', '。', '第一部', '我', '看', '哭', '了', '。', '这', '一部', '失落', '哭', '了', '。', '星爷', '！', '成龙', '也', '出过', '轨生', '了', '小龙女', '，', '但', '他', '演技', '所有人', '看到', '了', '！', '文章', '虽然', '某', '方面', '做错', '了', '，', '但', '真的', '演', '唐僧', '演', '的', '很', '到位', '！', '凡凡', '真的', '只', '适合', '看'] 1\n[' ', '因为', '上映', '的', '时候', '一直', '没', '时间', '去', '影院', '看', '，', '遗憾', '了', '很', '久', '，', '今天', '终于', '有', '时间', '看', '了', '。', '更', '遗憾', '没有', '去', '影院', '看', '了', '。', '哎', '！', '简直', '太棒了', '~'] 0\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ntrain_ds=list(zip(x_train,y_train))\n# 通过Dataset构建DataLoader\ntrain_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, \n                        collate_fn=build_collate_fun(vocab))\n\nvalid_ds=list(zip(x_valid,y_valid))\n# 通过Dataset构建DataLoader\nvalid_dl = DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=True, \n                        collate_fn=build_collate_fun(vocab))\ntest_ds=list(zip(x_test,y_test))\n# 通过Dataset构建DataLoader\ntest_dl = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, \n                        collate_fn=build_collate_fun(vocab))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T03:10:20.825371Z","iopub.execute_input":"2025-04-22T03:10:20.825894Z","iopub.status.idle":"2025-04-22T03:10:23.055253Z","shell.execute_reply.started":"2025-04-22T03:10:20.825872Z","shell.execute_reply":"2025-04-22T03:10:23.054485Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"print(len(vocab))\ni=0\nfor key in vocab.keys():\n    if key=='PAD':\n        print(key,vocab[key])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T03:10:57.876915Z","iopub.execute_input":"2025-04-22T03:10:57.877183Z","iopub.status.idle":"2025-04-22T03:10:57.946454Z","shell.execute_reply.started":"2025-04-22T03:10:57.877162Z","shell.execute_reply":"2025-04-22T03:10:57.945892Z"}},"outputs":[{"name":"stdout","text":"282378\nPAD 119816\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"###模型构建\n\nmodel = Comments_Classifier(len(vocab), EMBEDING_SIZE, RNN_HIDDEN_SIZE, NUM_LABELS)\n# 定义损失函数和优化器\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=LEARN_RATE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T03:11:00.844205Z","iopub.execute_input":"2025-04-22T03:11:00.844869Z","iopub.status.idle":"2025-04-22T03:11:03.628978Z","shell.execute_reply.started":"2025-04-22T03:11:00.844846Z","shell.execute_reply":"2025-04-22T03:11:03.628445Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"from tqdm import tqdm\n\ndef train(model,train_dl,criterion,optimizer):\n    global train_loss_cnt\n    model.to(device)\n    model.train()\n    tpbar=tqdm(train_dl)\n    for tokens,labels in tpbar:\n        optimizer.zero_grad()\n        tokens,labels=tokens.to(device),labels.to(device)\n        loss=train_step(model,tokens,labels,criterion)\n        loss.backward()\n        optimizer.step()\n        tpbar.set_description(f\"epoch:{epoch+1} train_loss:{loss.item():.4f}\")\n        writer.add_scalar('train_loss',loss.item(),train_loss_cnt)\n        train_loss_cnt+=1\n\ndef train_step(model,tokens,labels,criterion):\n    logits=model(tokens)\n    loss=criterion(logits,labels)\n    return loss\n    \ndef validate(model,val_dl,criterion):\n    global val_loss_cnt,val_acc_cnt\n    model.to(device)\n    model.eval()\n    tpbar=tqdm(val_dl)\n    total_loss=0\n    total_acc=0\n\n    for tokens,labels in tpbar:\n        tokens,labels=tokens.to(device),labels.to(device)\n        loss,logits=validate_step(model,tokens,labels,criterion)\n        tpbar.set_description(f\"epoch:{epoch+1} val_loss:{loss.item():.4f}\")\n\n        total_loss+=loss.item()\n        total_acc+=(logits.argmax(dim=1)==labels).float().mean()\n    writer.add_scalar('val_avg_loss',total_loss/len(val_dl),val_loss_cnt)\n    val_loss_cnt+=1\n    ##计算准确率\n    writer.add_scalar('val_acc',total_acc/len(val_dl),val_acc_cnt)\n    val_acc_cnt +=1\n         \n\n\ndef validate_step(model,tokens,labels,criterion):\n    logits=model(tokens)\n    loss=criterion(logits,labels)\n    return loss,logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T03:11:04.828646Z","iopub.execute_input":"2025-04-22T03:11:04.829507Z","iopub.status.idle":"2025-04-22T03:11:04.838640Z","shell.execute_reply.started":"2025-04-22T03:11:04.829483Z","shell.execute_reply":"2025-04-22T03:11:04.837792Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"##训练\nfor epoch in range(EPOCHS):\n    train(model,train_dl,criterion,optimizer)\n    validate(model,valid_dl,criterion)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T03:11:08.033805Z","iopub.execute_input":"2025-04-22T03:11:08.034250Z","iopub.status.idle":"2025-04-22T03:31:07.874783Z","shell.execute_reply.started":"2025-04-22T03:11:08.034220Z","shell.execute_reply":"2025-04-22T03:31:07.874187Z"}},"outputs":[{"name":"stderr","text":"epoch:1 train_loss:0.2015: 100%|██████████| 10407/10407 [03:52<00:00, 44.76it/s]\nepoch:1 val_loss:0.3379: 100%|██████████| 1301/1301 [00:09<00:00, 140.69it/s]\nepoch:2 train_loss:0.2056: 100%|██████████| 10407/10407 [03:50<00:00, 45.17it/s]\nepoch:2 val_loss:0.1723: 100%|██████████| 1301/1301 [00:09<00:00, 144.49it/s]\nepoch:3 train_loss:0.2181: 100%|██████████| 10407/10407 [03:50<00:00, 45.22it/s]\nepoch:3 val_loss:0.1424: 100%|██████████| 1301/1301 [00:09<00:00, 144.33it/s]\nepoch:4 train_loss:0.1425: 100%|██████████| 10407/10407 [03:50<00:00, 45.20it/s]\nepoch:4 val_loss:0.2334: 100%|██████████| 1301/1301 [00:08<00:00, 145.72it/s]\nepoch:5 train_loss:0.2072: 100%|██████████| 10407/10407 [03:51<00:00, 45.05it/s]\nepoch:5 val_loss:0.2621: 100%|██████████| 1301/1301 [00:08<00:00, 144.75it/s]\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"##保存模型\ntorch.save({'model_state': model.state_dict(),\n            'model_vocab':vocab},'model_jieba.bin')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T03:44:43.137781Z","iopub.execute_input":"2025-04-22T03:44:43.138030Z","iopub.status.idle":"2025-04-22T03:44:44.130685Z","shell.execute_reply.started":"2025-04-22T03:44:43.138013Z","shell.execute_reply":"2025-04-22T03:44:44.129841Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"# 创建模型实例\nmodel_test = Comments_Classifier(len(vocab), EMBEDING_SIZE, RNN_HIDDEN_SIZE, NUM_LABELS)\n\n# 加载保存的文件\ncheckpoint = torch.load('model_jieba.bin',weights_only=False)\n\n# 加载模型的状态字典\nmodel_test.load_state_dict(checkpoint['model_state'])\n\n# 加载词汇表\nvocab_test = checkpoint['model_vocab']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T03:45:45.647647Z","iopub.execute_input":"2025-04-22T03:45:45.647911Z","iopub.status.idle":"2025-04-22T03:45:46.667298Z","shell.execute_reply.started":"2025-04-22T03:45:45.647893Z","shell.execute_reply":"2025-04-22T03:45:46.666500Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"print(\"Model device:\", next(model_test.parameters()).device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T03:53:08.993001Z","iopub.execute_input":"2025-04-22T03:53:08.993475Z","iopub.status.idle":"2025-04-22T03:53:08.997712Z","shell.execute_reply.started":"2025-04-22T03:53:08.993451Z","shell.execute_reply":"2025-04-22T03:53:08.997006Z"}},"outputs":[{"name":"stdout","text":"Model device: cuda:0\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"###测试模型\ntpbar=tqdm(test_ds)\ni=0\nfor tokens,labels in tpbar:\n    model_test.eval()\n    model_test.to(device)\n    comment1_idx = torch.tensor([vocab_test.get(word, vocab_test['<UNK>']) for word in tokens])\n    comment1_idx = comment1_idx.unsqueeze(0).to(device)  # 添加batch维度    \n    predict=model_test(comment1_idx)\n    if torch.argmax(predict, dim=1).item()==labels:\n        i=i+1\nprint(f\"测试集正确率：{i/len(test_ds):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:02:45.885225Z","iopub.execute_input":"2025-04-22T04:02:45.885485Z","iopub.status.idle":"2025-04-22T04:05:30.357818Z","shell.execute_reply.started":"2025-04-22T04:02:45.885468Z","shell.execute_reply":"2025-04-22T04:05:30.357142Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 130087/130087 [02:44<00:00, 790.97it/s]","output_type":"stream"},{"name":"stdout","text":"测试集正确率：0.8987\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":56}]}