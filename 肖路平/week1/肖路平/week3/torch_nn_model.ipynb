{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "#X输入层 shape(,784)\n",
    "# 隐藏层 shape(784,64) #参数矩阵\n",
    "# 隐藏层 shape(64,) #偏置bias\n",
    "\n",
    "# 输出层 shape(64,10) #参数矩阵\n",
    "# 输出层 shape(10,) #偏置bias\n",
    "# Y 输出 shape(,10) #10个分类\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0876, 0.1044, 0.0616, 0.1047, 0.0886, 0.1419, 0.1006, 0.0996, 0.1366,\n",
       "         0.0744],\n",
       "        [0.0762, 0.1039, 0.0530, 0.1066, 0.0941, 0.1378, 0.0904, 0.1186, 0.1350,\n",
       "         0.0844],\n",
       "        [0.0907, 0.1151, 0.0614, 0.1059, 0.0895, 0.1413, 0.0953, 0.0965, 0.1231,\n",
       "         0.0811],\n",
       "        [0.0763, 0.1022, 0.0508, 0.1025, 0.0946, 0.1652, 0.0892, 0.1124, 0.1247,\n",
       "         0.0822],\n",
       "        [0.0748, 0.1009, 0.0654, 0.1081, 0.0833, 0.1465, 0.0981, 0.1105, 0.1310,\n",
       "         0.0814],\n",
       "        [0.0760, 0.1131, 0.0587, 0.1209, 0.0795, 0.1525, 0.0876, 0.1073, 0.1262,\n",
       "         0.0782],\n",
       "        [0.0832, 0.1077, 0.0608, 0.1261, 0.0903, 0.1477, 0.0788, 0.1011, 0.1258,\n",
       "         0.0785],\n",
       "        [0.0843, 0.1097, 0.0508, 0.1275, 0.0906, 0.1481, 0.0773, 0.1003, 0.1314,\n",
       "         0.0800],\n",
       "        [0.0830, 0.0971, 0.0603, 0.1218, 0.0757, 0.1393, 0.0850, 0.1080, 0.1382,\n",
       "         0.0918],\n",
       "        [0.0812, 0.1030, 0.0649, 0.1215, 0.0894, 0.1442, 0.0749, 0.1024, 0.1421,\n",
       "         0.0765]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#线性层\n",
    "linear = nn.Linear(in_features=784,out_features=64,bias=True) #in_features指的是特征个数，out_features指的是输出个数，bias是否需要偏置\n",
    "\n",
    "#激活函数\n",
    "act =nn.Sigmoid() #利用函数赋值\n",
    "###输出层\n",
    "linear2 = nn.Linear(in_features=64,out_features=10,bias=True)\n",
    " \n",
    "x = torch.randn(10,784) #10个样本，每个样本784个特征\n",
    "out=linear(x)\n",
    "out2=act(out)\n",
    "out3=linear2(out2)\n",
    "out3\n",
    "\n",
    "softmax =nn.Softmax(dim=1)#Softmax可计算概率，dim=1指定维度为进行softmax的维度\n",
    "final=softmax(out3)\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=64, bias=True)\n",
       "  (1): Sigmoid()\n",
       "  (2): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model =nn.Sequential(\n",
    "    nn.Linear(784, 64),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(64, 10) \n",
    "    )\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#损失函数\n",
    "loss_fn = nn.CrossEntropyLoss()#交叉熵损失函数\n",
    "#优化器（模型参数更新）\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)#model.parameters()包含所有模型参数，lr是学习率 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
