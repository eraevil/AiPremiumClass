{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 配置路径\n",
    "INPUT_DIR = '/kaggle/input/chinese-couplets/couplet/'\n",
    "TRAIN_IN_PATH = os.path.join(INPUT_DIR, 'train/in.txt')\n",
    "TRAIN_OUT_PATH = os.path.join(INPUT_DIR, 'train/out.txt')\n",
    "TEST_IN_PATH = os.path.join(INPUT_DIR, 'test/in.txt')\n",
    "TEST_OUT_PATH = os.path.join(INPUT_DIR, 'test/out.txt')\n",
    "OUTPUT_DIR = '/kaggle/working/'\n",
    "MODEL_SAVE_PATH = os.path.join(OUTPUT_DIR, 'seq2seq_concat.pth')\n",
    "LOG_DIR = os.path.join(OUTPUT_DIR, 'runs/concat_attention')\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "class Vocabulary:\n",
    "    pad_token = '<PAD>'\n",
    "    unk_token = '<UNK>'\n",
    "    bos_token = '<BOS>'\n",
    "    eos_token = '<EOS>'\n",
    "    \n",
    "    def __init__(self, vocab_dict):\n",
    "        self.vocab = vocab_dict\n",
    "        self.inv_vocab = {v:k for k,v in vocab_dict.items()}\n",
    "        self.pad_token_id = self.vocab[self.pad_token]\n",
    "        self.unk_token_id = self.vocab[self.unk_token]\n",
    "        self.bos_token_id = self.vocab[self.bos_token]\n",
    "        self.eos_token_id = self.vocab[self.eos_token]\n",
    "\n",
    "    def __getitem__(self, token):\n",
    "        return self.vocab.get(token, self.vocab[self.unk_token])\n",
    "\n",
    "    @classmethod\n",
    "    def from_files(cls, file_paths):\n",
    "        tokens = [cls.pad_token, cls.unk_token, cls.bos_token, cls.eos_token]\n",
    "        for file_path in file_paths:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                tokens.extend(line.strip().split())\n",
    "        unique_tokens = sorted(set(tokens))\n",
    "        return cls({tk:i for i, tk in enumerate(unique_tokens)})\n",
    "\n",
    "class CoupletDataset(Dataset):\n",
    "    def __init__(self, in_path, out_path, vocab):\n",
    "        self.enc_data = [line.strip() for line in open(in_path, 'r', encoding='utf-8')]\n",
    "        self.dec_data = [line.strip() for line in open(out_path, 'r', encoding='utf-8')]\n",
    "        self.vocab = vocab\n",
    "        assert len(self.enc_data) == len(self.dec_data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.enc_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        enc = self.enc_data[idx]\n",
    "        dec = ['<BOS>'] + self.dec_data[idx].split() + ['<EOS>']\n",
    "        enc_ids = [self.vocab[tk] for tk in enc]\n",
    "        dec_ids = [self.vocab[tk] for tk in dec]\n",
    "        return torch.tensor(enc_ids), torch.tensor(dec_ids)\n",
    "\n",
    "class ConcatAttention(nn.Module):\n",
    "    def __init__(self, encoder_hidden_dim, decoder_hidden_dim):\n",
    "        super().__init__()\n",
    "        self.encoder_hidden_dim = encoder_hidden_dim\n",
    "        self.decoder_hidden_dim = decoder_hidden_dim\n",
    "        self.W = nn.Linear(encoder_hidden_dim + decoder_hidden_dim, decoder_hidden_dim)\n",
    "        self.V = nn.Linear(decoder_hidden_dim, 1)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, encoder_outputs.size(1), 1)\n",
    "        combined = torch.cat((hidden, encoder_outputs), dim=2)\n",
    "        energy = torch.tanh(self.W(combined))\n",
    "        attention = torch.softmax(self.V(energy).squeeze(2), dim=1)\n",
    "        context = torch.bmm(attention.unsqueeze(1), encoder_outputs)\n",
    "        return attention, context\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=emb_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            bidirectional=True,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        return outputs, hidden\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, encoder_hidden_dim, decoder_hidden_dim):\n",
    "        super().__init__()\n",
    "        self.encoder_hidden_dim = encoder_hidden_dim\n",
    "        self.decoder_hidden_dim = decoder_hidden_dim\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=emb_dim + encoder_hidden_dim * 2,\n",
    "            hidden_size=decoder_hidden_dim,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc_out = nn.Linear(encoder_hidden_dim * 2 + decoder_hidden_dim + emb_dim, output_dim)\n",
    "        self.attention = ConcatAttention(encoder_hidden_dim * 2, decoder_hidden_dim)\n",
    "\n",
    "    def forward(self, x, encoder_outputs, hidden):\n",
    "        batch_size = x.size(0)\n",
    "        trg_len = x.size(1)\n",
    "        \n",
    "        outputs = torch.zeros(batch_size, trg_len, self.fc_out.out_features).to(x.device)\n",
    "        input = x[:, 0].unsqueeze(1)\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            embedded = self.embedding(input)\n",
    "            attn_weights, context = self.attention(hidden[-1], encoder_outputs)\n",
    "            rnn_input = torch.cat([embedded, context], dim=2)\n",
    "            output, hidden = self.rnn(rnn_input, hidden)\n",
    "            prediction = self.fc_out(torch.cat([embedded.squeeze(1), context.squeeze(1), hidden[-1]], dim=1))\n",
    "            outputs[:, t] = prediction\n",
    "            input = prediction.argmax(1).unsqueeze(1)\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, enc_vocab_size, dec_vocab_size, emb_dim, encoder_hidden_dim, decoder_hidden_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(enc_vocab_size, emb_dim, encoder_hidden_dim)\n",
    "        self.decoder = Decoder(dec_vocab_size, emb_dim, encoder_hidden_dim * 2, decoder_hidden_dim)\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "        return self.decoder(trg, encoder_outputs, hidden)\n",
    "\n",
    "def custom_collate(batch, vocab):\n",
    "    enc_seqs, dec_seqs = zip(*batch)\n",
    "    max_enc_len = max(len(s) for s in enc_seqs)\n",
    "    max_dec_len = max(len(s) for s in dec_seqs)\n",
    "    \n",
    "    padded_enc = [torch.cat([s, torch.full((max_enc_len - len(s),), vocab.pad_token_id)]) \n",
    "                  for s in enc_seqs]\n",
    "    padded_dec = [torch.cat([s, torch.full((max_dec_len - len(s),), vocab.eos_token_id)]) \n",
    "                  for s in dec_seqs]\n",
    "    \n",
    "    return pad_sequence(padded_enc, batch_first=True), pad_sequence(padded_dec, batch_first=True)\n",
    "\n",
    "def train_model():\n",
    "    vocab = Vocabulary.from_files([TRAIN_IN_PATH, TRAIN_OUT_PATH, TEST_IN_PATH, TEST_OUT_PATH])\n",
    "    train_dataset = CoupletDataset(TRAIN_IN_PATH, TRAIN_OUT_PATH, vocab)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=lambda b: custom_collate(b, vocab))\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = Seq2Seq(\n",
    "        enc_vocab_size=len(vocab.vocab),\n",
    "        dec_vocab_size=len(vocab.vocab),\n",
    "        emb_dim=256,\n",
    "        encoder_hidden_dim=256,\n",
    "        decoder_hidden_dim=512\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=vocab.pad_token_id)\n",
    "    writer = SummaryWriter(LOG_DIR)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    for epoch in range(10):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in tqdm(train_loader, desc=f'Epoch {epoch+1}'):\n",
    "            src, trg = batch\n",
    "            src, trg = src.to(device), trg.to(device)\n",
    "            output = model(src, trg[:, :-1])\n",
    "            output = output.view(-1, output.size(-1))\n",
    "            target = trg[:, 1:].view(-1)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        val_loss = evaluate_model(model, test_loader, vocab)\n",
    "        writer.add_scalars('Loss', {'train': total_loss/len(train_loader), 'val': val_loss}, epoch)\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "    \n",
    "    writer.close()\n",
    "\n",
    "def evaluate_model(model, data_loader, vocab):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            src, trg = batch\n",
    "            src, trg = src.to(device), trg.to(device)\n",
    "            output = model(src, trg[:, :-1])\n",
    "            output = output.view(-1, output.size(-1))\n",
    "            target = trg[:, 1:].view(-1)\n",
    "            loss = criterion(output, target)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "def generate_couplet(input_text, model, vocab, max_len=50):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        enc_tokens = input_text.split()\n",
    "        enc_ids = [vocab[tk] for tk in enc_tokens]\n",
    "        src_tensor = torch.tensor([enc_ids]).to(device)\n",
    "        encoder_outputs, hidden = model.encoder(src_tensor)\n",
    "        \n",
    "        dec_input = torch.tensor([[vocab.bos_token_id]]).to(device)\n",
    "        decoded_tokens = []\n",
    "        for _ in range(max_len):\n",
    "            output, hidden = model.decoder(dec_input, encoder_outputs, hidden)\n",
    "            topv, topi = output.topk(1)\n",
    "            next_token = topi.item()\n",
    "            if next_token == vocab.eos_token_id:\n",
    "                break\n",
    "            decoded_tokens.append(next_token)\n",
    "            dec_input = topi.unsqueeze(0)\n",
    "        return ' '.join([vocab.inv_vocab[token] for token in decoded_tokens])\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 训练模型\n",
    "train_model()\n",
    "\n",
    "# 示例推理\n",
    "test_input = \"天增岁月人增寿\"\n",
    "print(f\"Input: {test_input}\")\n",
    "prediction = generate_couplet(test_input, model, vocab)\n",
    "print(f\"Prediction: {prediction}\")\n",
    "\n",
    "# 保存词汇表\n",
    "with open(os.path.join(OUTPUT_DIR, 'vocab.json'), 'w') as f:\n",
    "    json.dump(vocab.inv_vocab, f, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
